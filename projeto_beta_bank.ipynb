{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detenção de Evasão no Beta Bank: Prevenindo a Rotatividade de Clientes com Análise de Dados\n",
    "\n",
    "No cenário atual, o **Beta Bank** enfrenta um desafio crescente: a evasão constante de clientes. Mês a mês, uma parcela significativa dos clientes abandona o banco, o que representa um custo elevado e uma ameaça à sustentabilidade do negócio. Através de análises internas, o banco identificou que manter um cliente existente é consideravelmente mais econômico do que adquirir um novo.\n",
    "\n",
    "Diante deste cenário, surge a necessidade crítica de desenvolver estratégias eficientes para prevenir a perda de clientes. A chave para esta solução repousa na **análise de dados** – uma abordagem que permite prever com precisão a probabilidade de um cliente deixar o banco. Utilizando dados históricos sobre o comportamento dos clientes e registros de rescisões de contratos, podemos construir um modelo preditivo robusto.\n",
    "\n",
    "Este projeto de análise de dados visa criar um sistema capaz de identificar sinais precoces de insatisfação ou propensão à evasão entre os clientes. Ao compreender os padrões e tendências nas atividades dos clientes, bem como os fatores que influenciam a decisão de deixar o banco, seremos capazes de implementar medidas proativas para aumentar a retenção de clientes.\n",
    "\n",
    "Além de identificar os clientes em risco, o projeto busca desenvolver estratégias personalizadas para abordar as necessidades específicas de cada segmento de cliente, aumentando assim a eficácia das ações de retenção. Este esforço não apenas fortalece a relação do Beta Bank com seus clientes existentes, mas também contribui para a construção de uma base de clientes mais leal e satisfeita a longo prazo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importação de bibliotecas \n",
    "\n",
    "Antes de embarcarmos em qualquer análise de dados, é crucial importar as bibliotecas certas para o ambiente de codificação. As bibliotecas contêm conjuntos de ferramentas e funções que nos permitem executar tarefas específicas, variando desde a manipulação de dados até a visualização e análise estatística. Ao importar bibliotecas apropriadas, estamos essencialmente equipando nosso ambiente com as ferramentas necessárias para conduzir a análise de maneira eficaz e eficiente. Em projetos de análise de dados, é comum usar bibliotecas como pandas para manipulação de dados, matplotlib e seaborn para visualização, e scikit-learn para modelagem, entre outras. A importação de bibliotecas é, portanto, um passo fundamental e preliminar que estabelece a base para as etapas subsequentes da análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plot\n",
    "import statistics\n",
    "import scipy.stats as stats\n",
    "import datetime as dt\n",
    "from scipy.stats import probplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats as st\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# importanto bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/Churn.csv')\n",
    "except:\n",
    "    data = pd.read_csv(r'C:\\Users\\PC\\Desktop\\portifolio 2\\projeto 8\\Churn.csv') # armazenando o conjunto de dados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observação de dados \n",
    "\n",
    "Agora é o momento de ter o nosso primeiro contato com os dados. Vamos identificar quais dados estão disponíveis, bem como possíveis problemas que possam estar presentes, como a ausência de informações, dados armazenados com o tipo incorreto, entre outros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "5     8.0  113755.78              2          1               0   \n",
       "6     7.0       0.00              2          1               1   \n",
       "7     4.0  115046.74              4          1               0   \n",
       "8     4.0  142051.07              2          0               1   \n",
       "9     2.0  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10) # imprimindo as primeiras 10 linhas do conjunto de dados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RowNumber — índice das strings de dados\n",
    "* CustomerId — identificador exclusivo do cliente\n",
    "* Surname — sobrenome\n",
    "* CreditScore — pontuação de crédito\n",
    "* Geography — país de residência\n",
    "* Gender — gênero\n",
    "* Age — idade\n",
    "* Tenure — tempo de serviço para o cliente\n",
    "* Balance — saldo da conta\n",
    "* NumOfProducts — número de produtos bancários usados pelo cliente\n",
    "* HasCrCard — cliente possui cartão de crédito (1 - sim; 0 - não)\n",
    "* IsActiveMember — cliente ativo (1 - sim; 0 - não)\n",
    "* EstimatedSalary — salário estimado\n",
    "* Exited — o cliente saiu (1 - sim; 0 - não)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info() #imprmindo informações gerais do conjunto de dados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somente uma coluna apresenta valores ausentes, a coluna: 'tenure', as demais caracteristicas apresentam os tipos corretor de dados, apesar de ser aconselhaveu usar somente letras minusculas nos seus respectivos nomes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe() #imprimindo valores estatisticos de colunas quantitativas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Métricas Estatísticas Básicas:**\n",
    "   - Através da análise de tendências centrais e de dispersão, como média e desvio padrão, obtemos uma compreensão mais profunda da distribuição e da variabilidade dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré processamento de dados.\n",
    "\n",
    "O pré-processamento de dados é o conjunto de técnicas e etapas aplicadas para preparar e limpar os dados brutos, garantindo que estejam prontos para análises posteriores. Isso envolve a remoção de ruídos, tratamento de valores ausentes, normalização e outras transformações necessárias para obter dados de qualidade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.lower() #transformando o nome de todas as colunas somente em letras minusculas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ter todos os nomes de colunas em minúsculos remove qualquer inconsistência causada por variações na capitalização. Isso é particularmente útil em ambientes de programação onde a diferenciação entre maiúsculas e minúsculas pode levar a erros ou confusões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates() #eliminando duplicatas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exclusão de Duplicatas:*\n",
    "  - Após a identificação, procedemos com a remoção dessas entradas duplicadas.\n",
    "  - Este processo assegura que cada transação no dataset seja única e represente um evento distinto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsão de Evasão de Clientes em Bancos com Aprendizado de Máquina\n",
    "\n",
    "O desafio da evasão de clientes, ou churn, é significativo no setor bancário. O uso de técnicas de aprendizado de máquina (ML) tem se mostrado fundamental na previsão e na mitigação desse fenômeno.\n",
    "\n",
    "## Aspectos Cruciais\n",
    "\n",
    "### Escolha do Modelo de ML\n",
    "- **Opções**: Árvores de Decisão, Florestas Aleatórias, Regressão Logística, SVM, Redes Neurais.\n",
    "- **Seleção**: Depende da complexidade dos dados e do objetivo de negócio.\n",
    "\n",
    "### Treinamento e Teste\n",
    "- **Processo**: Divisão dos dados em conjuntos de treinamento e teste.\n",
    "- **Objetivo**: Avaliar a eficácia do modelo.\n",
    "\n",
    "### Métricas de Avaliação\n",
    "- **Principais Métricas**: Precisão, Recall, F1-Score, AUC-ROC.\n",
    "- **Matriz de Confusão**: Fornece detalhes sobre o desempenho do modelo.\n",
    "\n",
    "### Validação Cruzada e Ajuste de Hiperparâmetros\n",
    "- **Validação Cruzada**: Essencial para a generalização do modelo.\n",
    "- **Ajuste de Hiperparâmetros**: Otimiza o desempenho do modelo.\n",
    "\n",
    "### Interpretabilidade do Modelo\n",
    "- **Importância**: Compreender os fatores que influenciam as previsões.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ohe = data.drop(columns={'surname', 'rownumber', 'customerid'})\n",
    "data_ohe = pd.get_dummies(data_ohe, drop_first=True)\n",
    "data_ohe['tenure'].fillna(data_ohe['tenure'].median(), inplace=True)\n",
    "target = data_ohe['exited']\n",
    "features = data_ohe.drop('exited', axis=1)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.15, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Remoção de Colunas**: Eliminar colunas que não contribuem para a análise, como identificadores únicos e informações pessoais.\n",
    "2. **One-Hot Encoding**: Converter variáveis categóricas em uma forma que possa ser fornecida aos modelos de machine learning.\n",
    "3. **Tratamento de Valores Ausentes**: Lidar com eventuais valores ausentes na coluna `tenure`.\n",
    "4. **Separação da Variável Alvo**: Definir qual é a variável alvo (`target`) que queremos prever. Neste caso, é a coluna 'exited'.\n",
    "5. **Separação das Características (Features)**: Separar as características usadas para prever a variável alvo.\n",
    "6. **Divisão em Conjuntos de Treino e Validação**: Dividir os dados em dois conjuntos - um para treinar o modelo e outro para validar seu desempenho.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `upsample` é utilizada para balancear classes em um conjunto de dados para modelos de classificação. Ela separa os dados em classes (zeros e uns), replica os dados da classe minoritária (aqui indicada por `repeat` vezes) e concatena de volta com a classe majoritária. Por fim, embaralha os dados balanceados usando a função `shuffle` com `random_state=12345` para garantir reprodutibilidade. O resultado é um conjunto de dados com classes mais equilibradas, ideal para treinar modelos de classificação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5967741935483871\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=1234), \n",
    "    params, \n",
    "    n_iter=10,  # Número de combinações de hiperparâmetros a serem testadas\n",
    "    cv=3,       # Reduzindo o número de folds\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,  # Usando todos os núcleos disponíveis\n",
    "    random_state=1234\n",
    ")\n",
    "random_search.fit(features_train, target_train)\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "predicted_valid = best_model.predict(features_valid)\n",
    "\n",
    "# Calculando o F1 Score\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.612954186413902\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'class_weight':['balanced']\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=1234), \n",
    "    params, \n",
    "    n_iter=10,  # Número de combinações de hiperparâmetros a serem testadas\n",
    "    cv=3,       # Reduzindo o número de folds\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,  # Usando todos os núcleos disponíveis\n",
    "    random_state=1234\n",
    ")\n",
    "random_search.fit(features_train, target_train)\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "predicted_valid = best_model.predict(features_valid)\n",
    "\n",
    "# Calculando o F1 Score\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para maximizar o desempenho do nosso modelo, realizaremos um ajuste fino dos hiperparâmetros. Utilizaremos `GridSearchCV` para automatizar o processo de busca pelos melhores hiperparâmetros para o `RandomForestClassifier`. Os hiperparâmetros que ajustaremos incluem:\n",
    "\n",
    "1. **n_estimators**: Número de árvores na floresta.\n",
    "2. **max_depth**: Profundidade máxima das árvores.\n",
    "3. **min_samples_split**: Número mínimo de amostras necessárias para dividir um nó interno.\n",
    "4. **min_samples_leaf**: Número mínimo de amostras necessárias para estar em um nó folha.\n",
    "5. **class_weight**: Ponderações das classes para lidar com desequilíbrios de classe.\n",
    "\n",
    "O objetivo é encontrar a combinação de hiperparâmetros que resulte no maior F1 Score, uma métrica que equilibra precisão e recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.3671199011124845\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1:', f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.455531453362256\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear', class_weight ='balanced')\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1:', f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código utiliza um modelo de Regressão Logística do `scikit-learn` para classificação. Primeiro, o modelo é instanciado com `random_state=12345` para garantir resultados consistentes e `solver='liblinear'`, ideal para conjuntos menores. Em seguida, ele é treinado com `features_upsampled` e `target_upsampled`, indicando o uso de técnicas de balanceamento de classe como o upsampling. Após treinamento, o modelo faz previsões no conjunto de validação (`features_valid`) e a eficácia é avaliada pela pontuação F1, que combina precisão e revocação, sendo útil em classes desequilibradas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.4859504132231405\n"
     ]
    }
   ],
   "source": [
    "decision_tree_model = DecisionTreeClassifier(random_state=1234, class_weight ='balanced')\n",
    "decision_tree_model.fit(features_upsampled, target_upsampled)\n",
    "predictions = decision_tree_model.predict(features_valid)\n",
    "f1 = f1_score(target_valid, predictions)\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5306799336650083\n"
     ]
    }
   ],
   "source": [
    "decision_tree_model = DecisionTreeClassifier(random_state=1234)\n",
    "decision_tree_model.fit(features_upsampled, target_upsampled)\n",
    "predictions = decision_tree_model.predict(features_valid)\n",
    "f1 = f1_score(target_valid, predictions)\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código implementa um modelo de Árvore de Decisão para classificação usando `scikit-learn`. Inicialmente, cria-se o modelo com `DecisionTreeClassifier`, definindo `random_state=1234` para resultados consistentes e `class_weight='balanced'` para ajustar automaticamente os pesos em classes desequilibradas. O modelo é treinado com dados balanceados (`features_upsampled` e `target_upsampled`). Após o treinamento, são feitas previsões no conjunto de validação (`features_valid`) e a eficácia é avaliada pelo F1 Score, uma métrica que considera precisão e revocação, útil em classes desequilibradas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Ao analisar diferentes modelos de aprendizado de máquina, observa-se uma melhoria significativa no desempenho ao aplicar técnicas de balanceamento de classe e ajuste de limiar de classificação. Os resultados, medidos pelo F1 Score, para cada modelo antes e após estas alterações são os seguintes:\n",
    "\n",
    "- **Random Forest:**\n",
    "  - Antes: F1 Score: 0.5967741935483871\n",
    "  - Depois: F1 Score: 0.612954186413902\n",
    "\n",
    "- **Regressão Logística:**\n",
    "  - Antes: F1: 0.3671199011124845\n",
    "  - Depois: F1: 0.455531453362256\n",
    "\n",
    "- **Árvore de Decisão:**\n",
    "  - Antes: F1 Score: 0.4859504132231405\n",
    "  - Depois: F1 Score: 0.5306799336650083\n",
    "\n",
    "Conforme evidenciado pelos valores de F1 Score, a **Random Forest** apresenta a melhor métrica após a aplicação das técnicas de balanceamento e ajuste de limiar, demonstrando sua maior eficácia em relação aos outros modelos analisados.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
